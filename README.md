The python notebook contain the code to inference LLM using google colab Not the optimal way to use the compute but can be useful to beginners 

Note: inferenced only gguf models 
TPU is optimized for high core cpu inference 
T4 is optimized for GPU off loading 

